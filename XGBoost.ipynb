{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date                  datetime64[ns]\n",
      "Open                         float64\n",
      "High                         float64\n",
      "Low                          float64\n",
      "Close                        float64\n",
      "Adj Close                    float64\n",
      "Volume                         int64\n",
      "sp500return                  float64\n",
      "CPIAUCSL                     float64\n",
      "FEDFUNDS                     float64\n",
      "mktrf                        float64\n",
      "smb                          float64\n",
      "hml                          float64\n",
      "rf                           float64\n",
      "umd                          float64\n",
      "GDP                          float64\n",
      "PPIACO                       float64\n",
      "T10Y2Y                       float64\n",
      "T10Y3M                       float64\n",
      "T10YFF                       float64\n",
      "consumer_sentiment           float64\n",
      "VIXCLS                       float64\n",
      "WM2NS                        float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('cleaned_data.csv')\n",
    "\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "df['T10Y3M'] = pd.to_numeric(df['T10Y3M'], errors='coerce')\n",
    "df['T10YFF'] = pd.to_numeric(df['T10YFF'], errors='coerce')\n",
    "df['T10Y2Y'] = pd.to_numeric(df['T10Y2Y'], errors='coerce')\n",
    "\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qc/y3rkgtfd5rx9y0s0c8pqdwh00000gn/T/ipykernel_39877/793286478.py:19: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  X_train = X[~is_test].drop('Date', axis=1)\n",
      "/var/folders/qc/y3rkgtfd5rx9y0s0c8pqdwh00000gn/T/ipykernel_39877/793286478.py:21: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  X_test = X[is_test].drop('Date', axis=1)\n"
     ]
    }
   ],
   "source": [
    "window_size = 20\n",
    "df['target'] = df['Close'].rolling(window=window_size).mean()\n",
    "df['target'] = df['target'].pct_change()\n",
    "df['target'] = df['target'].apply(lambda x: 1 if x > 0.0001 else (-1 if x < -0.0001 else 0))\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "y = y.shift(-1)\n",
    "y.dropna(inplace=True)\n",
    "X = X.iloc[:len(y)]\n",
    "\n",
    "start_date = pd.to_datetime(\"2018-01-01\")\n",
    "end_date = pd.to_datetime(\"2021-12-31\")\n",
    "\n",
    "# 创建一个布尔序列，指示每行数据是否属于测试集\n",
    "is_test = (df['Date'] >= start_date) & (df['Date'] <= end_date)\n",
    "\n",
    "X_train = X[~is_test].drop('Date', axis=1)\n",
    "y_train = y[~is_test]\n",
    "X_test = X[is_test].drop('Date', axis=1)\n",
    "y_test = y[is_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total data: 3968\n",
      "training data: 2998\n",
      "y training data: 2998\n",
      "testing data: 969\n",
      "y testing data: 969\n"
     ]
    }
   ],
   "source": [
    "print(f'total data: {df.shape[0]}')\n",
    "print(f'training data: {X_train.shape[0]}')\n",
    "print(f'y training data: {y_train.shape[0]}')\n",
    "print(f'testing data: {X_test.shape[0]}')\n",
    "print(f'y testing data: {y_test.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{-1.0: 998, 0.0: 139, 1.0: 1861}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique, counts = np.unique(y_train.values, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "调参：使用时间序列交叉验证器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 250}\n"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [2, 3, 4],\n",
    "    'n_estimators': [150,200,250],\n",
    "    'learning_rate': [0.01, 0.1, 0.5]\n",
    "}\n",
    "\n",
    "model = xgb.XGBClassifier(objective='multi:softprob', num_class=3)  # 适用于你的三分类任务\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=3)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=tscv, scoring='accuracy')  # 使用准确度作为评分指标\n",
    "\n",
    "grid_search.fit(X_train, y_train_encoded)\n",
    "\n",
    "print(\"Best parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5748194014447885\n"
     ]
    }
   ],
   "source": [
    "model = grid_search.best_estimator_\n",
    "y_pred_encoded = model.predict(X_test)\n",
    "\n",
    "y_pred = label_encoder.inverse_transform(y_pred_encoded)\n",
    "\n",
    "accuracy = accuracy_score(y_test_encoded, y_pred_encoded)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "调参：使用贝叶斯优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:06<00:00,  1.50trial/s, best loss: -0.7058299955496218]\n",
      "The best hyperparameters are :  \n",
      "\n",
      "{'colsample_bytree': 0.5280025235020058, 'gamma': 0.1641097714897643, 'learning_rate': 0.15311594393133118, 'max_depth': 3.0, 'min_child_weight': 4.0, 'n_estimators': 300.0}\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def objective(space):\n",
    "    clf = xgb.XGBClassifier(\n",
    "        n_estimators =int(space['n_estimators']), \n",
    "        max_depth = int(space['max_depth']), \n",
    "        learning_rate = space['learning_rate'],\n",
    "        min_child_weight = space['min_child_weight'],\n",
    "        gamma = space['gamma'],\n",
    "        colsample_bytree = space['colsample_bytree']\n",
    "    )\n",
    "    \n",
    "    accuracy = cross_val_score(clf, X_train, y_train_encoded, cv=TimeSeriesSplit(n_splits=3), scoring=\"accuracy\").mean()\n",
    "\n",
    "    return {'loss': -accuracy, 'status': STATUS_OK }\n",
    "\n",
    "\n",
    "space = {\n",
    "    'max_depth': hp.quniform('max_depth', 3, 12, 1),\n",
    "    'n_estimators': hp.quniform('n_estimators', 50, 500, 50),\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.01, 0.2),\n",
    "    'min_child_weight': hp.quniform('min_child_weight', 1, 6, 1),\n",
    "    'gamma': hp.uniform('gamma', 0, 0.5),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.3, 1)\n",
    "}\n",
    "\n",
    "\n",
    "trials = Trials()\n",
    "best_hyperparams = fmin(fn = objective,\n",
    "                        space = space,\n",
    "                        algo = tpe.suggest,\n",
    "                        max_evals = 100,\n",
    "                        trials = trials)\n",
    "\n",
    "print(\"The best hyperparameters are : \",\"\\n\")\n",
    "print(best_hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6202270381836945\n"
     ]
    }
   ],
   "source": [
    "best_params = {\n",
    "    'max_depth': int(best_hyperparams['max_depth']),\n",
    "    'n_estimators': int(best_hyperparams['n_estimators']),\n",
    "    'learning_rate': best_hyperparams['learning_rate'],\n",
    "    'min_child_weight': best_hyperparams['min_child_weight'],\n",
    "    'gamma': best_hyperparams['gamma'],\n",
    "    'colsample_bytree': best_hyperparams['colsample_bytree']\n",
    "}\n",
    "\n",
    "# 创建并训练XGBoost模型\n",
    "model_2 = xgb.XGBClassifier(objective='multi:softprob', num_class=3, **best_params)\n",
    "model_2.fit(X_train, y_train_encoded)\n",
    "\n",
    "# 进行预测\n",
    "y_pred_encoded_2 = model_2.predict(X_test)\n",
    "\n",
    "y_pred_2 = label_encoder.inverse_transform(y_pred_encoded_2)\n",
    "\n",
    "# 计算准确度\n",
    "accuracy = accuracy_score(y_test_encoded, y_pred_encoded_2)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
